{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch functions : utilizing torch.tensor  \n",
    "\n",
    "### Probability distribution functions in Tensor\n",
    "\n",
    "PyTorch is an open-source framework that is used in Machine Learning applications such as Computer Vision and Natural Language Processing. One of the advantage of PyTorch is that, it is using GPU's to deliver a faster performance in advanced and complex deep learning projects. It also has a very useful feature called data parralelism, where PyTorch distributes computational work among multiple GPU and CPU cores.\n",
    "\n",
    "PyTorch is extremely compatible with Python because, it is built to be seamlessly integrated with python programming language and it's popular library NumPy. The syntax is also very familiar with Python programing language.\n",
    "\n",
    "A Tensor in PyTorch is basically a numpy array or just a list (in layman terms). We use Tensor so the GPUs can process it at it's core. \n",
    "\n",
    "Formal definition : A Tensor is a generic n-dimensional array to be used for arbitrary numeric computation.\n",
    "In this post, I will cover 5 functions using the tensor.\n",
    "\n",
    "- torch.tensor\n",
    "- torch.tensor.backward()\n",
    "- torch.tensor.bernoulli()\n",
    "- torch.tensor.geometric()\n",
    "- torch.tensor.log_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 - torch.tensor\n",
    "Let's begin with creating a tensor in Python. A Tensor can be constructed from a Python list or sequence using \n",
    "torch.tensor() constructor. We can also create an array by calling NumPy inside the tensor: Below are both the examples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working \n",
    "torch.tensor([[1, 2], [3, 4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example 2 - creating Tensor using numpy array\n",
    "torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch.tensor will create an array with the default 32-bit float data type (torch.float32). A tensor of specific data type can be constructed by passing a torch.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3 - creating a tensor with all zeros and 32-bit integer data type\n",
    "torch.zeros([2, 4], dtype = torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.zeros will create a tensor with all elements being 0 inside. It takes columns and rows as it's parameter. The second parameter is the data type which is 32- bit integer. Recall, the default is torch.float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 2 at dim 1 (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-28787d136593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 2 at dim 1 (got 3)"
     ]
    }
   ],
   "source": [
    "# Example 4 - breaking (to illustrate when it breaks)\n",
    "torch.tensor([[1, 2], [3, 4, 5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breaking illustrations shows that torch.tensor will not work if the matrix does not have consistent dimensions. Each list needs to have the same amount of elements in the tensor for it to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  3,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [45, 66,  7],\n",
       "        [23, 34, 23],\n",
       "        [ 2,  0,  9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example 4 - extreme output\n",
    "torch.tensor([[1,2,3], [4,3,2],[3,4,5], [45,66,7],\n",
    "               [23,34, 23], [2,0,9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing comments : This function is almost always used when creating an empty tensor. We can also create a random tensor by calling in torch.tensor(x,y) which will populate the Tensor with random values from the range x to y (not including)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 - torch.tensor.backward()\n",
    "\n",
    "This function computes the gradient of current tensor w.r.t the graph leaves. It calculates the gradient by passing itâ€™s argument (1x1 unit tensor by default) through the backward graph all the way up to every leaf node traceable from the calling root tensor. By default, pytorch expects backward() to be called for the last output of the network - the loss function. The loss function always outputs a scalar and therefore, backwards() can only be called on a scalar tensor and expects no arguments. The gradients of the scalar loss w.r.t all other variables/parameters is well defined using the chain rule.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - working : Taking a derivative of x^3\n",
    "import torch\n",
    "#Create a tensor\n",
    "x = torch.tensor(1.0, requires_grad = True )\n",
    "z = x ** 3\n",
    "#compute the gradient\n",
    "z.backward()\n",
    "# prints 3.0 or 3 which is dz/dx\n",
    "print(x.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example illustrates how to comute a gradient of a tensor using the backward function. The tensor was x^3 which was stored in z. Afterwards, z.backward() computes the gradient and then finally the data is printed using grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(4.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - working : Taking a derivative w.r.t another variable y\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0, requires_grad = True)\n",
    "z = torch.tensor(6.0, requires_grad = True)\n",
    "\n",
    "var = x **3 + y ** 2 + z\n",
    "var.backward()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 variables x, y, and z where x does not have requires_grad set to True. What that means is, PyTorch will automatically compute the derivative of var w.r.t the tensors that have requires_grad set to True. That's excatly what backward() method will do when called upon the variable var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tensor() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7533b96d1470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tensor() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "import torch\n",
    "x = torch.tensor(4.0, 5.0, 6.0, requires_grad = True)\n",
    "\n",
    "var = x ** 2 \n",
    "var.backward()\n",
    "print(x.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example illustrates what was discussed in the intro of the function. The backward function will only take a scalar as a parameter. If we try to pass in a vector or an array/list the function will generate a TypeError. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, this function is used to compute a derivative on a scalar one dimensional Tensor. The argument requires_grad will need to be set to True in order to compute the derivative for a particular variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - tensor.torch.bernoulli_()\n",
    "\n",
    "Bernoulli distribution is a discrete probability function that has two possible outcomes n = 0 and n = 1 in which        n = 1(success) occurs with probability <i>p </i> and   n = 0 occurs with probability <i>q </i> = <i>1 - p </i> ,      where 0 < p < 1. Below examples will demonstrate the function with a Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working \n",
    "import torch\n",
    "var = torch.Tensor(3,3).bernoulli_(p = 0.5, generator = None)\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example creates a Tensor which has 3 columns and 3 rows. We pass in parameter p = 0.5, which is the probability that the distribution will result into either a success or a failure by 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "var = torch.Tensor([[0.4, 0.5, 0.9], [0.1, 0.7, 0.88]])\n",
    "sample = torch.Tensor(2, 3).bernoulli_(var, generator = None)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In example 2, we have created a new Tensor that is containing multiple probabilities to be used for drawing the binary random number. The ith value can be accessed by Bernoulli_( var[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected p_in >= 0 && p_in <= 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-395330701e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.88\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbernoulli_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected p_in >= 0 && p_in <= 1 to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "var = torch.Tensor([[1, 23, 90], [0.1, 0.7, 0.88]])\n",
    "sample = torch.Tensor(2, 3).bernoulli_(var, generator = None)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Example 3, I have used the same code from example 2. I only made a minor change to break the code. The tensor that is being passed into the bernoulli function has values with integer data types. Probabilities are always measured in floating point values. So, the tensor being passed must have all floating point values to perform the Bernoulli distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing comments about when to use this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - torch.tensor.geometric_()\n",
    "Formal Definition : The geometric distribution is the probability distribution of the number of failures we get by repeating a Bernoulli experiment until we obtain the first success.\n",
    "\n",
    "Mathematical definition : https://mathworld.wolfram.com/GeometricDistribution.html\n",
    "\n",
    "Explanation : Geometric distribution is the probability distribution of the number of tails one must flip before the first head using a weighted coin. It is useful for modeling situations in which it is necessary to know how many attempts are likely necessary for success, and thus has applications to population modeling, econometrics, return on investment (ROI) of research, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 1.],\n",
       "        [2., 1., 1.],\n",
       "        [7., 2., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "var = torch.Tensor(3,3).geometric_(p = 0.777, generator = None)\n",
    "var"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In example - 1, we have built a Tensor with 3 columns and 3 rows, and set the probabilty parameter <i>p = 0.777 </i>. \n",
    "After we create a Tensor, the geometric function drawselements in the the geometric distribution : tensor with elements drawn from the geometric distribution:\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 2.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "var = torch.Tensor(3,3,2).geometric_(0.1)\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In example 2, we created a tensor with 3 dimensions with the probability set to 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "geometric_ expects p to be in (0, 1), but got p=2.4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-4124413db526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometric_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: geometric_ expects p to be in (0, 1), but got p=2.4"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "var = torch.Tensor(3,3,2).geometric_(2.4)\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same example is being used from example 2. This time we tried to break the code by putting in a probabilistic value that is greater than 1. We got a RuntimeError because probability is always within the range (0,1). Probability is bever greater than 100, hence the code did not work"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 - torch.tensor.log_normal_()\n",
    "\n",
    "Formal Definition : Lognormal distribution is a continuous probabilistic distribution of a random variable whose logarithm is normally distrbuted. So, if a variable X is log-normally distributed, the Y = log(X) has a nornal distribution.\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Mathematical definition : https://mathworld.wolfram.com/LogNormalDistribution.html\n",
    "\n",
    "Explanation : The log-normal distribution is the probability distribution of a random variable whose logarithm follows a normal distribution. It models phenomena whose relative growth rate is independent of size, which is true of most natural phenomena including the size of tissue and blood pressure, income distribution, and even the length of chess games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  10.6182,   11.2088,    3.0453],\n",
       "        [1872.3538, 2170.0347,   15.1384]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "import torch\n",
    "var = torch.Tensor(2,3).log_normal_(mean = 3, std = 4, generator = None)\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, we create a Tensor with 2 columns and 3 rows with the log normal distribution. Here, the distribution function itself takes in two parameters; mean and standard deviation. Each random element in the Tensor will be passed into the normal distribution sample and computed for a log normal distribution as per the formula in the introduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5118e+07, 9.9392e+06, 4.6896e+07, 2.4135e+08, 1.4839e+09, 1.1571e+10,\n",
       "         7.5695e+05, 1.0684e+11, 4.3572e+09],\n",
       "        [2.3158e+09, 8.9958e+08, 3.6649e+09, 3.2194e+11, 3.5958e+07, 1.6201e+08,\n",
       "         5.7553e+07, 1.5329e+10, 3.8494e+07],\n",
       "        [7.4035e+08, 1.7455e+08, 2.9421e+08, 5.1662e+08, 1.4577e+08, 7.8826e+09,\n",
       "         8.6048e+09, 2.1665e+07, 4.6394e+08],\n",
       "        [3.1268e+06, 1.0006e+09, 3.8396e+10, 3.9422e+10, 9.6389e+07, 6.8669e+07,\n",
       "         5.1719e+09, 5.0927e+09, 1.4440e+09],\n",
       "        [3.3573e+07, 2.3888e+08, 1.5435e+07, 3.1746e+09, 1.7063e+09, 2.5437e+06,\n",
       "         1.1832e+09, 3.2230e+09, 3.1358e+07],\n",
       "        [2.1640e+10, 5.6778e+10, 7.0112e+05, 4.1133e+08, 4.2252e+10, 5.3675e+06,\n",
       "         2.3047e+08, 4.0432e+07, 3.1704e+07]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "#var = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "sample = torch.Tensor(6,9).log_normal_(mean = 20, std = 3)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example is similar to example 1, except for extreme output eneration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "log_normal_ expects std > 0.0, but found std=-3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-619397797390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: log_normal_ expects std > 0.0, but found std=-3"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "sample = torch.Tensor(6,9).log_normal_(mean = 20, std = - 3)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same code is being used in example 3 as example 2. The only operation not allowed here is a negative mean or standard deviation. Hence, when entered a negative value, the code breaks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We discussed in this post about how to create a Tensor and how a tensor can be used in different probabilistic distributions go generate complex results. With this intro, we are now ready to build our own Machine Learning model using a Tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "Provide links to your references and other interesting articles about tensors\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html\n",
    "* https://brilliant.org/wiki/log-normal-distribution/\n",
    "* https://brilliant.org/wiki/bernoulli-distribution/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n",
      "[jovian] Updating notebook \"smitj23/01-tensor-operations\" on https://jovian.ml/\u001b[0m\n",
      "[jovian] Uploading notebook..\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ml/smitj23/01-tensor-operations\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ml/smitj23/01-tensor-operations'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
